{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "580758e3-c202-4526-9ea3-d945b9a1865f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 2: Data Exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d3e97cf-667a-46b4-9e4f-3ac16a33addf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7540ada-940d-4523-8d19-1d5759c8517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset path\n",
    "dataset_path = \"EuroSAT/2750/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caac1d87-cdcf-4411-8486-cd634ad2eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all land type categories\n",
    "categories = os.listdir(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f12034-ca92-4f12-88d6-1c228df455cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 3: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d05cab-c30b-4d48-9089-5b1738e4ee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3edd8b8-017b-4d12-a3ea-81bc12a1feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize, normalize, and convert to RGB\n",
    "def load_and_preprocess_images(path, size=(64, 64)):\n",
    "    data, labels = [], []\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(path, category)\n",
    "        for img_name in os.listdir(category_path):\n",
    "            img = cv2.imread(os.path.join(category_path, img_name))\n",
    "            img = cv2.resize(img, size)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "            img = img / 255.0  # Normalize to [0,1]\n",
    "            data.append(img)\n",
    "            labels.append(category)\n",
    "    return np.array(data, dtype=\"float32\"), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f8c6529-1af7-4793-a180-19055e22a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data, labels = load_and_preprocess_images(dataset_path, size=(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96f8fc09-adac-46c1-9c78-0dbe8f986924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfde6993-87d5-4637-bf88-aed0769f611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels into integers\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)  # Convert category names to integer labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24e3dce9-cbf9-4de4-9bec-20126297e3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to one-hot encoding\n",
    "labels_categorical = to_categorical(labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ede2900-1f48-4573-a163-6879be5073a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train (70%), validation (20%), and test (10%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(data, labels_categorical, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=1/3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "448a0fab-6336-4e58-af34-cca5e19c538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    # shear_range=15,\n",
    ")\n",
    "\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=25,    # Slightly increased, but not too much\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     shear_range=0.1  # Just a little shear (not too aggressive)\n",
    "# )\n",
    "\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     zoom_range=0.2,\n",
    "#     shear_range=0.15,   # Skewing effect for robustness\n",
    "#     brightness_range=[0.8, 1.2],  # simulates lighting variation\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f64106e-e0b0-4620-9a11-1a26e4ba874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_datagen = ImageDataGenerator()\n",
    "\n",
    "# Final datasets\n",
    "train_generator = datagen.flow(X_train, y_train, batch_size=32, shuffle=True)\n",
    "val_generator = val_test_datagen.flow(X_val, y_val, batch_size=32, shuffle=False)\n",
    "test_generator = val_test_datagen.flow(X_test, y_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f8602d-9bad-407e-9579-9cc5fce8823e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Step 4: Modelling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4c6d56-55ca-43e3-bd9b-165ca19f8b39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2be1684f-4214-4dd5-828d-a57bc3783414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization, GlobalAveragePooling2D, Dropout, Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad0ff7de-3a25-4e20-b25e-4c0c66205cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf20796-c18f-4228-a996-f04f62b78802",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988f58ac-966b-4208-9f40-a2547137b0ff",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83394f93-557f-4d8a-9c43-9f291f7c9cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Evaluate Keras Model\n",
    "def evaluate_model(model, X_test, y_test, class_names):\n",
    "    # Get model predictions\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n",
    "    y_true = np.argmax(y_test, axis=1)  # Convert one-hot encoded labels to class indices\n",
    "\n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred) * 100  # Convert to percentage\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    # Print classification report\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "    print(f\"Final Accuracy: {accuracy:.2f}%\")  # Print final accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87af5a0f-34b9-4c76-baca-3f297e4bcdd3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31e2937-d9f7-44b6-9fa3-71b858321f41",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks (CNN)\n",
    "#### üîπ Definition\n",
    "A **Convolutional Neural Network (CNN)** is a deep learning model designed for image processing tasks. It automatically extracts features from images using convolutional layers.\n",
    "\n",
    "#### üîπ Key Components\n",
    "- **Convolutional Layers**: Detect patterns using filters (kernels)\n",
    "- **Pooling Layers**: Reduce dimensions while preserving features\n",
    "- **Fully Connected Layers**: Classify the extracted features\n",
    "- **Activation Functions**: Typically ReLU for non-linearity\n",
    "\n",
    "#### üîπ Advantages\n",
    "‚úÖ Captures spatial relationships in images  \n",
    "‚úÖ Reduces number of parameters compared to traditional networks  \n",
    "‚úÖ Suitable for image classification, object detection, and segmentation  \n",
    "‚úÖ no manual feature extraction & engineering needed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb09cac7-8d15-4376-910e-03acd38b783a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52442890-1009-4e1f-bf49-b7e892c69b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build improved CNN model\n",
    "def build_model():\n",
    "    model = models.Sequential([\n",
    "        # Input(shape=(64, 64, 3)),\n",
    "        Input(shape=(128, 128, 3)),\n",
    "\n",
    "        layers.Conv2D(32, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Conv2D(128, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        layers.Conv2D(256, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        layers.Conv2D(512, (3, 3), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(256),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Dropout(0.4),\n",
    "        Dense(len(categories), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dcebeb-57e6-4970-a4d9-49184b241b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2de0b5-3f91-4f55-99cb-65ffa07f8560",
   "metadata": {},
   "source": [
    "### üß† **CNN** Model Architecture ‚Äì Full Explanation\n",
    "\n",
    "This document explains the architecture and logic behind the custom Convolutional Neural Network (CNN) model used to classify EuroSAT satellite images.\n",
    "\n",
    "---\n",
    "\n",
    "#### üì• Input Layer\n",
    "```python\n",
    "Input(shape=(128, 128, 3))\n",
    "```\n",
    "- Defines the shape of the input images.\n",
    "- 128√ó128 pixels with 3 RGB channels.\n",
    "- Essential for compatibility with model layers.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîÅ Convolutional Layers\n",
    "\n",
    "Each Layer extracts increasingly abstract spatial features.\n",
    "\n",
    "#### üîπ Layer 1\n",
    "```python\n",
    "Conv2D(32, (3, 3), padding='same')\n",
    "BatchNormalization()\n",
    "LeakyReLU(alpha=0.1)\n",
    "MaxPooling2D((2, 2))\n",
    "```\n",
    "- 32 filters for edge detection and textures.\n",
    "- BatchNormalization stabilizes learning.\n",
    "- LeakyReLU prevents dead neurons.\n",
    "- MaxPooling reduces spatial size.\n",
    "\n",
    "#### üîπ Layer 2\n",
    "```python\n",
    "Conv2D(64, (3, 3), padding='same')\n",
    "BatchNormalization()\n",
    "LeakyReLU(alpha=0.1)\n",
    "MaxPooling2D((2, 2))\n",
    "```\n",
    "- Deeper filters (64) capture more complex features.\n",
    "- Follows same structure as Block 1.\n",
    "\n",
    "#### üîπ Layer 3\n",
    "```python\n",
    "Conv2D(128, (3, 3), padding='same')\n",
    "BatchNormalization()\n",
    "LeakyReLU(alpha=0.1)\n",
    "MaxPooling2D((2, 2))\n",
    "Dropout(0.25)\n",
    "```\n",
    "- Adds dropout for regularization.\n",
    "- More filters for deeper representations.\n",
    "\n",
    "#### üîπ Layer 4\n",
    "```python\n",
    "Conv2D(256, (3, 3), padding='same')\n",
    "BatchNormalization()\n",
    "LeakyReLU(alpha=0.1)\n",
    "MaxPooling2D((2, 2))\n",
    "Dropout(0.25)\n",
    "```\n",
    "- 256 filters for high-level abstraction.\n",
    "- Continues downsampling and regularizing.\n",
    "\n",
    "#### üîπ Layer 5\n",
    "```python\n",
    "Conv2D(512, (3, 3), padding='same')\n",
    "BatchNormalization()\n",
    "LeakyReLU(alpha=0.1)\n",
    "MaxPooling2D((2, 2))\n",
    "Dropout(0.25)\n",
    "```\n",
    "- 512 filters: top-level spatial features.\n",
    "- Final convolutional layer before pooling.\n",
    "\n",
    "---\n",
    "\n",
    "#### üåç Feature Aggregation\n",
    "\n",
    "```python\n",
    "GlobalAveragePooling2D()\n",
    "```\n",
    "- Averages each feature map into a single number.\n",
    "- Reduces dimensionality, avoids overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "#### üß† Dense Layers (Classifier)\n",
    "\n",
    "```python\n",
    "Dense(256)\n",
    "LeakyReLU(alpha=0.1)\n",
    "Dropout(0.4)\n",
    "Dense(len(categories), activation='softmax')\n",
    "```\n",
    "- Dense(256): learns patterns from feature maps.\n",
    "- Dropout(0.4): prevents overfitting.\n",
    "- Final Dense uses softmax for classification across 10 EuroSAT classes.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚öôÔ∏è Compilation\n",
    "\n",
    "```python\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "```\n",
    "- Adam: adaptive optimizer for faster convergence.\n",
    "- Categorical crossentropy: suitable for multi-class classification.\n",
    "- Accuracy as the evaluation metric.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚è±Ô∏è Callbacks\n",
    "\n",
    "```python\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "```\n",
    "- EarlyStopping halts training if val_loss stagnates for 5 epochs.\n",
    "- ReduceLROnPlateau decreases learning rate for finer convergence.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4385ab84-42d7-410a-976d-babbc34366a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model Training (Fitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f3109-9c64-4968-884b-058fc09f8031",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 64 resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042deef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building\n",
    "model_64 = build_model()\n",
    "\n",
    "# Train the model\n",
    "history = model_64.fit(\n",
    "    train_generator,\n",
    "    epochs=60,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de70ed8-0d04-4453-9191-49c2b83734dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model_64, test_generator, y_test, class_names=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327bdf2e-ebc0-4514-84ce-447bc5030165",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 128 resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d127404e-1b04-4642-8a03-fc9e8d0362f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model_128 = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5ff183-70cc-407d-ba2e-aad4248a86e3",
   "metadata": {},
   "source": [
    "#### üèãÔ∏è Training Process\n",
    "\n",
    "```python\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=60,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "```\n",
    "- Trains up to 60 epochs with validation monitoring.\n",
    "- Uses generators for memory-efficient data loading.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6575c3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model_128.fit(\n",
    "    train_generator,\n",
    "    epochs=60,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8565313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "evaluate_model(model_128, test_generator, y_test, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98976fa1-db79-4c12-8a90-4b3a442cbb73",
   "metadata": {},
   "source": [
    "####  Final Accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7c18e6-2584-4de3-86ab-e9fa35a4c5b4",
   "metadata": {},
   "source": [
    "#### Plot Accuracy and Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c528f27-0694-4315-a373-aead8813d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a5b55d-7889-4637-b8fa-a884e5323ec5",
   "metadata": {},
   "source": [
    "#### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e329b00-f394-4294-ac2a-bfbe06f17856",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_128.save('better_cnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaffe98-bb0f-4329-ad39-87faa638f548",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Import and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8f58d2d-17c4-41cc-aa83-1bb076faff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9631661-edda-485b-85a5-17ccd26ccd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"best_cnn_model.h5\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497dd5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, test_generator, y_test, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228b2152-9f1d-4e1b-96b5-e65a92d868d2",
   "metadata": {},
   "source": [
    "### Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "020c15b8-dd6c-4527-9ce2-58e09798ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def predict_image(img_path, model, class_names):\n",
    "    # Step 1: Load image\n",
    "    original_img = image.load_img(img_path)\n",
    "    img = image.load_img(img_path, target_size=(128, 128))  # resize to match input\n",
    "\n",
    "    # Step 2: Convert to array\n",
    "    img_array = image.img_to_array(img)\n",
    "\n",
    "    # Step 3: Normalize (scale to 0-1)\n",
    "    img_array = img_array / 255.0\n",
    "\n",
    "    # Step 4: Expand dimensions (make it batch-like)\n",
    "    img_batch = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Step 5: Predict\n",
    "    prediction = model.predict(img_batch)\n",
    "    class_index = np.argmax(prediction)\n",
    "\n",
    "    # Step 6: Show result\n",
    "    predicted_label = class_names[class_index]\n",
    "    print(f\"Predicted Class: {predicted_label} ({prediction[0][class_index]*100:.2f}%)\")\n",
    "\n",
    "    # Optional: Display the image\n",
    "    plt.imshow(original_img)\n",
    "    plt.title(f\"Predicted: {predicted_label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ffe181-181a-4c74-b307-ee70ccf96415",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image(\"C:\", model, categories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
